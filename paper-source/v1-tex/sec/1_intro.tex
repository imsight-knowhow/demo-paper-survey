\section{Introduction}
\label{sec:intro}

Recently, there has been a growing trend in the commercialization of diffusion models \cite{rombach2022high,Saharia2022,BetkerImprovingIG,sora} for applications within the entertainment industry such as Metaverse, online video streaming, broadcasting, and even the robotic field \cite{chi2023diffusion}. A pertinent example is the use of diffusion models to create virtual YouTubers. These digital personas should be capable of reacting in a fluid and responsive manner to user input. These areas require diffusion pipelines that offer high throughput and low latency to ensure the efficient interactive streaming generation. 

To advance the efficiency, current efforts primarily focus on reducing the number of denoising steps, such as decreasing from 50 denoise steps to just a few \cite{luo2023latent,luo2023lcm} or even one \cite{yin2023onestep,liu2023insta}. The strategy includes distilling the multi-step diffusion models into a few steps \cite{sauer2023adversarial,song2023consistency} or re-framing the diffusion process with neural Ordinary Differential Equations (ODE) \cite{lu2022dpm,lu2022dpm+}. 
Quantization has also been applied to diffusion models \cite{li2023qdiffusion,huang2023tfmq} to improve efficiency. These methods share the common goal of approximating either the diffusion process itself or the original model weights to achieve efficiency gains.
In this paper, we aim at an orthogonal direction and introduce StreamDiffusion, a pipeline-level solution that enables streaming image generation with high throughput. We highlight that existing model design efforts can still be integrated with our pipeline. Our approach enables the use of N-step denoising diffusion models while keeping high throughput and offers users more flexibility in choosing their preferred models. 


\begin{figure*}[ht]
  \centering
   \includegraphics[width=\linewidth]{figure/system_concept.png}
\caption{The overview of StreamDiffusion. StreamDiffusion combines several key components: (1) Stream Batch efficiently processes the denoising steps in batches. (2) Residual Classifier-Free Guidance approximates the negative condition term to reduces the unnecessary repetitive calculations in the UNet. (3) Stochastic Similarity Filter controls the pass of the image stream by calculating the similarity between frames to eliminate the redundant hit onto GPUs. Furthermore, StreamDiffusion leverages techniques like input-output queues for smooth data flow, cache management for faster processing through pre-calculated embedding, and a tiny VAE model to further contribute to overall efficiency. This synergistic combination allows StreamDiffusion to generate high-quality images at high throughputs while consuming minimal energy. }
\vspace{-5mm}
\label{fig:overview}
\end{figure*}


Specifically, StreamDiffusion seamlessly incorporates a suite of novel strategies. Among these, we propose a simple yet novel approach termed \textbf{Stream Batch}. This method differs from the traditional sequential denoising mode, instead of batching the denoising steps. This subtle modification enhances efficiency without sacrificing the quality of image generation. We highlight Stream Batch enables a new capability of generating images conditioned on future frames in a streaming mode, which is something impossible in previous works. Via injecting the future frames, Stream Batch significantly improves the temporal consistency with few additional overhead.
Furthermore, the key novelty of Stream Batch lies not only in its GPU parallelization; rather, it serves as a practical realization of a broader Stream Denoising framework. By denoising inputs at diagonally-offset timesteps within a streaming queue structure, diffusion models naturally achieve continuous, autoregressive generation—emitting one output frame per each newly sampled frame—while benefiting from parallel computation. Crucially, this design generalizes directly to sequential tasks such as video, audio, or robotic action-sequence generation, enabling interactive, unbounded-length synthesis.

Besides, we point out that it is time-consuming for existing diffusion pipelines to use classifier-free guidance for emphasizing the prompts during generation, due to the repetitive and redundant computations for negative conditions. To address this issue, we introduce an innovative approach termed as \textbf{residual classifier-free guidance (R-CFG)}. R-CFG approximates the negative condition with a virtual residual noise, which allows us to calculate the negative condition noise only during the initial step of the process. We also indicate that using the original input image latent as the residual term effectively generates results that diverge from the original input image according to the magnitude of the guidance scale, which is a special case of our R-CFG and does not require any computations for the negative condition term. 

Furthermore, in real applications such as virtual youtuber and AR/VR cases, maintaining the diffusion models always in an active mode is energy-consuming as it keeps hitting GPU. To reduce the energy, we further apply a \textbf{stochastic similarity filtering (SSF)} strategy. In the pipeline, we compute the similarities between continuous inputs and determine whether the diffusion model should process the images based on the probability of an activated similarity. This enables both energy efficiency and visual fluency. In order to further improve the efficiency to cater to the real applications, we apply simple yet effective engineering implementations such as Input-Output Queue (IO-Queue), pre-computing caching, and TensorRT. The overview of the StreamDiffusion pipeline is shown in Fig. \ref{fig:overview}.

Experiments demonstrate that our proposed StreamDiffusion can achieve up to 91.07fps for image generation on one RTX4090 GPU, surpassing the diffusion Autopipeline from Diffusers \cite{diffusers} team by up to 59.6x. Besides, our stochastic similarity filtering strategy significantly reduces the GPU power usage by 2.39x on one RTX 3090GPU and by 1.99x on one RTX 4090GPU. Our proposed StreamDiffusion is a new diffusion pipeline that is not only efficient but also energy-saving. 


